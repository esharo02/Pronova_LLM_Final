{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pronova LLM Run Model #\n",
    "## Use this notebook to do the following ##\n",
    "- Run the current model on a query\n",
    "- start a flask api server that accepts a query and will return a response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load require libraries\n",
    "import os\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Qdrant connection ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to Qdrant\n"
     ]
    }
   ],
   "source": [
    "# Get the Qdrant API key from the environment variable\n",
    "Qdrant_api_key = os.getenv('Qdrant_API_KEY')\n",
    "if not Qdrant_api_key:\n",
    "    raise ValueError(\"No Qdrant API key found in environment variables\")\n",
    "Qdrant_url = os.getenv('Qdrant_URL')\n",
    "if not Qdrant_url:\n",
    "    raise ValueError(\"No Qdrant URL found in environment variables\")\n",
    "\n",
    "\n",
    "# Initialize Qdrant client\n",
    "try:\n",
    "    Qclient = QdrantClient(\n",
    "        url= Qdrant_url,\n",
    "        api_key=Qdrant_api_key\n",
    "    )\n",
    "    print(\"Successfully connected to Qdrant\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to connect to Qdrant: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup OpenAI connection ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the OpenAI API key from the environment variable\n",
    "OpenAI_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if not OpenAI_api_key:\n",
    "    raise ValueError(\"No OpenAI API key found in environment variables\")\n",
    "\n",
    "OpenAI.api_key = OpenAI_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get an OpenAI embedding from a text segment (Function) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the embedding of a text\n",
    "def get_embedding(text):\n",
    "    client = OpenAI()\n",
    "    response = client.embeddings.create(\n",
    "        model=\"text-embedding-ada-002\",\n",
    "        input=text\n",
    "    )\n",
    "    return response.data[0].embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve similar chunks from query (Function) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_relevant_chunks(collection_name, query, top_k=5, threshold=0.8):\n",
    "    query_embedding = get_embedding(query)\n",
    "    \n",
    "    search_result = Qclient.search(\n",
    "        collection_name=collection_name,\n",
    "        query_vector=query_embedding,\n",
    "        limit=top_k\n",
    "    )\n",
    "\n",
    "    filtered_results = [\n",
    "        result for result in search_result if result.score >= threshold\n",
    "    ]\n",
    "    \n",
    "\n",
    "    contexts = [result.payload[\"text\"] for result in filtered_results]\n",
    "    urls = [result.payload.get(\"url\") for result in filtered_results]\n",
    "    \n",
    "    return contexts, urls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank response source importance (Function) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def file_ratios(files):\n",
    "    total_files = len(files)\n",
    "    counts = Counter(files)\n",
    "    return {file: count*100 / total_files for file, count in counts.items()}\n",
    "\n",
    "\n",
    "# file_ratios([\"a\", \"a\", \"b\", \"c\"])\n",
    "# {'a': 0.5, 'b': 0.25, 'c': 0.25}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markdown Print Function ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_markdown(md_text):\n",
    "    display(Markdown(md_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Response from Query (Function) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_response(collection_name, query, all_query, all_context, all_responses, all_files):\n",
    "    print(\"Generating response for query:\", query)\n",
    "    # generate context for new query\n",
    "    context, files = retrieve_relevant_chunks(collection_name, query)\n",
    "    \n",
    "    if \"URL not found\" in files:\n",
    "        print(\"URL not found in files, removing it\")\n",
    "        # remove the URL not found from the list of files\n",
    "        files.remove(\"URL not found\")    \n",
    "\n",
    "    system_role = \"You are a specialized assistant that only provides advice on dog-related veterinary care. If a user asks about any other animal or topic outside of dog health, politely decline to answer and remind them that you only provide information about dogs. You will always start by asking the user their dog's name, age, and breed if they didn't already provide it.\"\n",
    "    # Combine retrieved chunks into a single string\n",
    "    context_text = \"\\n\".join(context)\n",
    "\n",
    "    if files:\n",
    "        # print(\"Adding new files: \", files)\n",
    "        all_files.extend(files)\n",
    "    # append query and context to the running lists\n",
    "    all_query.append(query)\n",
    "    all_context.append(context_text)\n",
    "\n",
    "    # print(\"All files used now:\", all_files)\n",
    "    # create the messages object using all the queries and contexts\n",
    "    messages = [{\"role\": \"system\", \"content\": system_role}]\n",
    "\n",
    "    for i in range(len(all_query)):\n",
    "        messages.append({\"role\": \"system\", \"content\": \"Use this context to answer my following question: \" + all_context[i]})\n",
    "        messages.append({\"role\": \"user\", \"content\": all_query[i]})\n",
    "        if i < len(all_responses):\n",
    "            messages.append({\"role\": \"system\", \"content\": all_responses[i]})\n",
    "    \n",
    "    # print(messages)\n",
    "\n",
    "\n",
    "    # Generate a response using GPT-4\n",
    "    client = OpenAI()\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini-2024-07-18\",\n",
    "        messages=messages\n",
    "    )\n",
    "    all_responses.append(completion.choices[0].message.content)\n",
    "    return all_query, all_context, all_responses, all_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# to confirm that each file has a properly stored citation\n",
    "def get_citation(filename):\n",
    "    # files_list = [\"../sources/sources_amva.json\", \" ../sources/sources_petMD_allergies.json\", \"/sources_petMD_behavior.json\",  \"/source.json\", \"/sources_petMD_care_healthy_living.json\", \"/sources_petMD_nutrition.json\", \"/sources_petMD_procedures.json\", \"/sources_petMD_symptoms.json\", \"/sources_petMD.json\"]\n",
    "    files_list = [f\"../sources/{file}\" for file in os.listdir(\"../sources\") if file.endswith('.json')]\n",
    "    # print(files_list)\n",
    "    citation = {}\n",
    "    \n",
    "    for file in files_list:\n",
    "        with open(file, 'r', encoding='utf-8') as f:\n",
    "            sources = json.load(f)\n",
    "            if filename in sources:\n",
    "                citation = sources[filename]\n",
    "                break\n",
    "    \n",
    "    url = citation.get('URL', 'URL not found')\n",
    "    author = citation.get('Author', 'Author not found')\n",
    "    date = citation.get('Date', 'Date not found')\n",
    "    topic = citation.get('Topic', 'Topic not found')\n",
    "    \n",
    "    \n",
    "    return topic, url, author, date\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playground (use this to test querys in the notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating response for query: My dog Bamba, a 5yo golden, has been limping after short walks.\n",
      "Adding new files:  ['https://www.petmd.com/dog/symptoms/why-is-my-dog-limping', 'https://www.petmd.com/dog/symptoms/why-is-my-dog-limping', 'https://www.petmd.com/dog/breeds/miniature-poodle', 'https://www.petmd.com/dog/symptoms/why-is-my-dog-limping', 'https://www.petmd.com//dog/conditions/musculoskeletal/c_dg_arthritis_septic']\n",
      "I'm sorry to hear that Bamba is limping. Limping in dogs can be caused by various issues, ranging from minor injuries to more serious conditions. Since Bamba has been experiencing limping after short walks, it would be a good idea to have him evaluated by your veterinarian as soon as possible. They can determine the underlying cause of the limping and recommend appropriate treatment.\n",
      "\n",
      "In the meantime, you should avoid any strenuous activities for Bamba and keep him comfortable. It’s best not to give him any medications without consulting your vet first. Providing low-impact exercise, like short and slow walks, can be beneficial, but it’s important to monitor his comfort levels during these activities.\n",
      "\n",
      "Make sure to keep an eye out for any signs of pain, swelling, or other concerning symptoms. Hopefully, Bamba feels better soon!\n",
      "https://www.petmd.com/dog/symptoms/why-is-my-dog-limping\n",
      "https://www.petmd.com/dog/symptoms/why-is-my-dog-limping\n",
      "https://www.petmd.com/dog/breeds/miniature-poodle\n",
      "https://www.petmd.com/dog/symptoms/why-is-my-dog-limping\n",
      "https://www.petmd.com//dog/conditions/musculoskeletal/c_dg_arthritis_septic\n"
     ]
    }
   ],
   "source": [
    "# Qclient.get_collections()\n",
    "collection_name = \"FullModel\"\n",
    "query = \"My dog Bamba, a 5yo golden, has been limping after short walks.\"\n",
    "query_list, context_list, response_list, files_list = generate_response(collection_name, query, [], [], [], [])\n",
    "\n",
    "\n",
    "print(response_list[0])\n",
    "for url in files_list:\n",
    "    print(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lightweight Flask Server (for Frontend API testing) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "\n",
    "collection_name = \"FullModel\" # for eyals db\n",
    "# collection_name = \"LLM_V1\"  # for other db\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)  # This will enable CORS for all routes\n",
    "\n",
    "@app.route('/query', methods=['POST'])\n",
    "def query_llm():\n",
    "    data = request.json\n",
    "    new_query = data.get('new_query')\n",
    "    queries = data.get('queries')\n",
    "    contexts = data.get('contexts')\n",
    "    responses = data.get('responses')\n",
    "    \n",
    "    # if not new_query or not queries or not contexts or not responses:\n",
    "    #     return jsonify({'error': 'New query, queries, contexts, and responses must be provided'}), 400\n",
    "\n",
    "    try:\n",
    "        updated_queries, updated_contexts, updated_responses = generate_response(collection_name, new_query, queries, contexts, responses)\n",
    "        return jsonify({\n",
    "            'queries': updated_queries,\n",
    "            'contexts': updated_contexts,\n",
    "            'responses': updated_responses\n",
    "        })\n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
