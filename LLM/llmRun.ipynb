{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pronova LLM Run Model #\n",
    "## Use this notebook to do the following ##\n",
    "- Run the current model on a query\n",
    "- start a flask api server that accepts a query and will return a response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load require libraries\n",
    "import os\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Qdrant connection ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to Qdrant\n"
     ]
    }
   ],
   "source": [
    "# Get the Qdrant API key from the environment variable\n",
    "Qdrant_api_key = os.getenv('Qdrant_API_KEY')\n",
    "if not Qdrant_api_key:\n",
    "    raise ValueError(\"No Qdrant API key found in environment variables\")\n",
    "Qdrant_url = os.getenv('Qdrant_URL')\n",
    "if not Qdrant_url:\n",
    "    raise ValueError(\"No Qdrant URL found in environment variables\")\n",
    "\n",
    "\n",
    "# Initialize Qdrant client\n",
    "try:\n",
    "    Qclient = QdrantClient(\n",
    "        url= Qdrant_url,\n",
    "        api_key=Qdrant_api_key\n",
    "    )\n",
    "    print(\"Successfully connected to Qdrant\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to connect to Qdrant: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup OpenAI connection ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the OpenAI API key from the environment variable\n",
    "OpenAI_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if not OpenAI_api_key:\n",
    "    raise ValueError(\"No OpenAI API key found in environment variables\")\n",
    "\n",
    "OpenAI.api_key = OpenAI_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get an OpenAI embedding from a text segment (Function) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the embedding of a text\n",
    "def get_embedding(text):\n",
    "    client = OpenAI()\n",
    "    response = client.embeddings.create(\n",
    "        model=\"text-embedding-ada-002\",\n",
    "        input=text\n",
    "    )\n",
    "    return response.data[0].embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve similar chunks from query (Function) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_relevant_chunks(collection_name, query, top_k=10):\n",
    "    query_embedding = get_embedding(query)\n",
    "    \n",
    "    search_result = Qclient.search(\n",
    "        collection_name=collection_name,\n",
    "        query_vector=query_embedding,\n",
    "        limit=top_k\n",
    "    )\n",
    "\n",
    "    contexts = [result.payload[\"text\"] for result in search_result]\n",
    "    files = [result.payload.get(\"source_file\") for result in search_result]\n",
    "    \n",
    "    return contexts, files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank response source importance (Function) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def file_ratios(files):\n",
    "    total_files = len(files)\n",
    "    counts = Counter(files)\n",
    "    return {file: count*100 / total_files for file, count in counts.items()}\n",
    "\n",
    "\n",
    "# file_ratios([\"a\", \"a\", \"b\", \"c\"])\n",
    "# {'a': 0.5, 'b': 0.25, 'c': 0.25}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markdown Print Function ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_markdown(md_text):\n",
    "    display(Markdown(md_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Response from Query (Function) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_response(collection_name, query, all_query, all_context, all_responses, all_files):\n",
    "    print(\"Generating response for query:\", query)\n",
    "    # generate context for new query\n",
    "    context, files = retrieve_relevant_chunks(collection_name, query)\n",
    "    \n",
    "    # print(\"Adding new files: \", files)\n",
    "    files_used = np.unique(files).tolist()\n",
    "    # files_used = file_ratios(files_used)\n",
    "\n",
    "    system_role = \"You are a specialized assistant that only provides advice on dog-related veterinary care. If a user asks about any other animal or topic outside of dog health, politely decline to answer and remind them that you only provide information about dogs. You will always start by asking the user their dog's name, age, and breed if they didn't already provide it.\"\n",
    "    # Combine retrieved chunks into a single string\n",
    "    context_text = \"\\n\".join(context)\n",
    "\n",
    "    # append query and context to the running lists\n",
    "    all_query.append(query)\n",
    "    all_context.append(context_text)\n",
    "    all_files.append(files_used)\n",
    "\n",
    "    # print(\"All files used now:\", all_files)\n",
    "    # create the messages object using all the queries and contexts\n",
    "    messages = [{\"role\": \"system\", \"content\": system_role}]\n",
    "\n",
    "    for i in range(len(all_query)):\n",
    "        messages.append({\"role\": \"system\", \"content\": \"Use this context to answer my following question: \" + all_context[i]})\n",
    "        messages.append({\"role\": \"user\", \"content\": all_query[i]})\n",
    "        if i < len(all_responses):\n",
    "            messages.append({\"role\": \"system\", \"content\": all_responses[i]})\n",
    "    \n",
    "    # print(messages)\n",
    "\n",
    "\n",
    "    # Generate a response using GPT-4\n",
    "    client = OpenAI()\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini-2024-07-18\",\n",
    "        messages=messages\n",
    "    )\n",
    "    all_responses.append(completion.choices[0].message.content)\n",
    "    return all_query, all_context, all_responses, all_files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playground (use this to test querys in the notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating response for query: My dog Bamba, a 5yo golden, has been limping after short walks.\n",
      "I'm sorry to hear that Bamba is limping. Limping can be a sign of pain or discomfort, and it's important to assess the severity of the situation. Since Bamba is limping after short walks, I recommend keeping her activity level low and providing her with plenty of rest. \n",
      "\n",
      "If her limp persists or she shows any other signs of pain, such as reluctance to bear weight on the leg, whining, or changes in behavior, it's best to make an appointment with your veterinarian. They can evaluate her properly and determine the underlying cause of her limping.\n",
      "\n",
      "Please avoid giving any medications at home until youâ€™ve consulted with the vet, as some might not be safe for dogs without a prescription. Make sure to monitor her condition closely and seek veterinary advice as soon as possible to ensure that Bamba gets the appropriate care.\n",
      "(' Dog Tail Injury: Signs and Causes', 'https://www.petmd.com//dog/conditions/dead-tail-dogs', 'Katie Grzyb, DVM', 'Apr. 28, 2022')\n",
      "(' Natural Treatments for Managing Arthritis in Dogs', 'https://www.petmd.com//dog/conditions/natural-treatments-managing-arthritis-dogs', 'PetMD Editorial', 'Oct. 18, 2016')\n",
      "(' Panosteitis in Dogs (Growing Pains in Dogs)', 'https://www.petmd.com//dog/conditions/musculoskeletal/c_multi_panosteitis', 'Emily A. Fassbaugh, DVM', 'Oct. 21, 2021')\n",
      "(' Septic Arthritis in Dogs', 'https://www.petmd.com//dog/conditions/musculoskeletal/c_dg_arthritis_septic', 'Melissa Boldan, DVM', 'Oct. 11, 2022')\n",
      "(' Why Is My Dog Limping?', 'https://www.petmd.com/dog/symptoms/why-is-my-dog-limping', 'Jennifer Coates, DVM', 'Apr. 4, 2024')\n"
     ]
    }
   ],
   "source": [
    "collection_name = \"FullModel\"\n",
    "query = \"My dog Bamba, a 5yo golden, has been limping after short walks.\"\n",
    "query_list, context_list, response_list, files_list = generate_response(collection_name, query, [], [], [], [])\n",
    "\n",
    "\n",
    "# # Qclient.get_collections()\n",
    "print(response_list[0])\n",
    "# print([file for file in files_list[0]])\n",
    "for file in files_list[0]:\n",
    "    # print(file)\n",
    "    cite = get_citation(file)\n",
    "    print(cite)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def get_citation(filename):\n",
    "    files_list = [\"scrapingDemo/sources_petMD_allergies.json\", \"scrapingDemo/sources_petMD_behavior.json\", \"scrapingDemo/sources_petMD_nutrition.json\", \"scrapingDemo/sources_petMD_care_healthy_living.json\", \"scrapingDemo/sources_petMD_procedures.json\", \"scrapingDemo/sources_petMD_symptoms.json\", \"scrapingDemo/sources_petMD.json\"]\n",
    "    citation = {}\n",
    "    \n",
    "    for file in files_list:\n",
    "        with open(file, 'r', encoding='utf-8') as f:\n",
    "            sources = json.load(f)\n",
    "            if filename in sources:\n",
    "                citation = sources[filename]\n",
    "                break\n",
    "    \n",
    "    url = citation.get('URL', 'URL not found')\n",
    "    author = citation.get('Author', 'Author not found')\n",
    "    date = citation.get('Date', 'Date not found')\n",
    "    topic = citation.get('Topic', 'Topic not found')\n",
    "    \n",
    "    \n",
    "    return topic, url, author, date\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lightweight Flask Server (for Frontend API testing) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "\n",
    "collection_name = \"FullModel\" # for eyals db\n",
    "# collection_name = \"LLM_V1\"  # for other db\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)  # This will enable CORS for all routes\n",
    "\n",
    "@app.route('/query', methods=['POST'])\n",
    "def query_llm():\n",
    "    data = request.json\n",
    "    new_query = data.get('new_query')\n",
    "    queries = data.get('queries')\n",
    "    contexts = data.get('contexts')\n",
    "    responses = data.get('responses')\n",
    "    \n",
    "    # if not new_query or not queries or not contexts or not responses:\n",
    "    #     return jsonify({'error': 'New query, queries, contexts, and responses must be provided'}), 400\n",
    "\n",
    "    try:\n",
    "        updated_queries, updated_contexts, updated_responses = generate_response(collection_name, new_query, queries, contexts, responses)\n",
    "        return jsonify({\n",
    "            'queries': updated_queries,\n",
    "            'contexts': updated_contexts,\n",
    "            'responses': updated_responses\n",
    "        })\n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
